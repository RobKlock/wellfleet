"""
Main Scanner Orchestrator
Coordinates all components to scan for weather arbitrage opportunities
"""

import logging
import os
from datetime import datetime
from pathlib import Path
from typing import List, Optional

from .kalshi_client import KalshiClient
from .nws_adapter import NWSAdapter
from .market_parser import MarketParser
from .mispricing_detector import MispricingDetector, Opportunity
from .report_generator import ReportGenerator


class KalshiWeatherScanner:
    """Main orchestrator for the Kalshi weather arbitrage scanner"""

    def __init__(
        self,
        email: Optional[str] = None,
        password: Optional[str] = None,
        api_key_id: Optional[str] = None,
        private_key_path: Optional[str] = None,
        bankroll: float = 1000.0,
        kelly_fraction: float = 0.25,
        min_edge_threshold: float = 0.20
    ):
        """
        Initialize the scanner with all components

        Args:
            email: Kalshi account email (for email/password auth)
            password: Kalshi account password (for email/password auth)
            api_key_id: API key ID (for API key auth)
            private_key_path: Path to private key file (for API key auth)
            bankroll: Total capital available for betting
            kelly_fraction: Fraction of Kelly criterion to use
            min_edge_threshold: Minimum edge required to flag opportunities
        """
        # Initialize components
        self.kalshi = KalshiClient(
            email=email,
            password=password,
            api_key_id=api_key_id,
            private_key_path=private_key_path
        )
        self.nws = NWSAdapter()
        self.parser = MarketParser()
        self.detector = MispricingDetector(
            bankroll=bankroll,
            kelly_fraction=kelly_fraction,
            min_edge_threshold=min_edge_threshold
        )
        self.reporter = ReportGenerator()

        # Setup logging
        self.logger = logging.getLogger(__name__)

    def scan(
        self,
        specific_tickers: Optional[List[str]] = None,
        series_tickers: Optional[List[str]] = None
    ) -> List[Opportunity]:
        """
        Main scanning process

        Args:
            specific_tickers: Optional list of specific market tickers to scan
            series_tickers: Optional list of series tickers to scan (e.g., KXLOWTDEN)

        Returns:
            List of identified opportunities
        """
        self.logger.info("=" * 60)
        self.logger.info("Starting Kalshi Weather Scanner")
        self.logger.info("=" * 60)

        # Determine which fetching method to use
        if series_tickers:
            self.logger.info(f"Scanning {len(series_tickers)} series...")
            weather_markets = self._fetch_markets_from_series(series_tickers)
        elif specific_tickers:
            self.logger.info(f"Scanning {len(specific_tickers)} specific markets...")
            weather_markets = self._fetch_specific_markets(specific_tickers)
        else:
            # Step 1: Fetch promo markets
            self.logger.info("Fetching promo markets from Kalshi...")
            promo_markets = self.kalshi.get_promo_markets()
            self.logger.info(f"Found {len(promo_markets)} promo markets")

            # Step 2: Filter for weather markets in Denver/Miami
            weather_markets = self._filter_weather_markets(promo_markets)
            self.logger.info(f"Found {len(weather_markets)} weather markets for Denver/Miami")

        if not weather_markets:
            self.logger.warning("No weather markets found. Scan complete.")
            return []

        # Step 3: Analyze each market
        opportunities = []

        for market in weather_markets:
            self.logger.info(f"Analyzing: {market['title'][:80]}...")

            try:
                # Parse market
                parsed = self.parser.parse(market["title"], market["ticker"])

                if not parsed.is_parseable:
                    self.logger.warning(f"  âš  Could not parse market: {market['ticker']}")
                    continue

                self.logger.info(
                    f"  âœ“ Parsed: {parsed.location}, {parsed.metric} "
                    f"{parsed.comparison} {parsed.threshold}Â°F on {parsed.date}"
                )

                # Get NWS forecast
                city, state = self._parse_location(parsed.location)
                if not city or not state:
                    self.logger.warning(f"  âš  Could not parse location: {parsed.location}")
                    continue

                forecast_periods = self.nws.get_forecast_for_city(city, state)

                # Extract stats for target date with meteorological data
                timezone = self.nws.LOCATIONS[parsed.location]["timezone"]
                forecast = self.nws.extract_temperature_stats_for_date(
                    forecast_periods,
                    parsed.date.isoformat(),
                    timezone,
                    include_meteorology=True  # Include sky cover, wind, dewpoint
                )

                if not forecast:
                    self.logger.warning(f"  âš  No forecast data available for {parsed.date}")
                    continue

                self.logger.info(
                    f"  âœ“ Forecast: min={forecast['min']:.1f}Â°F, "
                    f"max={forecast['max']:.1f}Â°F, avg={forecast['avg']:.1f}Â°F"
                )

                # Get current conditions and observations for boundary model
                current_conditions = None
                observations = None

                location_info = self.nws.LOCATIONS.get(parsed.location)
                if location_info and "station_id" in location_info:
                    station_id = location_info["station_id"]

                    try:
                        # Fetch current conditions
                        current_conditions = self.nws.get_current_conditions(station_id)

                        # Fetch recent observations (last 48 hours)
                        observations = self.nws.get_observations(station_id, hours=48)

                        if current_conditions:
                            self.logger.info(
                                f"  âœ“ Current: {current_conditions['temperature']:.1f}Â°F, "
                                f"wind={current_conditions['wind_speed']:.1f}mph, "
                                f"sky={current_conditions['sky_cover']}%"
                            )
                    except Exception as e:
                        self.logger.warning(f"  âš  Could not fetch current conditions: {e}")

                # Detect mispricing
                opp = self.detector.analyze_temperature_market(
                    market,
                    parsed,
                    forecast,
                    current_conditions=current_conditions,
                    observations=observations
                )

                if opp:
                    opportunities.append(opp)
                    self.logger.info(
                        f"  ðŸŽ¯ OPPORTUNITY: {opp.edge:+.1%} edge, "
                        f"bet {opp.recommended_side} for ${opp.recommended_bet_size:.2f}"
                    )
                else:
                    self.logger.info("  âœ“ Market efficiently priced")

            except Exception as e:
                self.logger.error(f"  âœ— Error analyzing market: {e}", exc_info=True)
                continue

        self.logger.info("=" * 60)
        self.logger.info(f"Scan complete. Found {len(opportunities)} opportunities.")
        self.logger.info("=" * 60)

        return opportunities

    def _fetch_markets_from_series(self, series_tickers: List[str]) -> List[dict]:
        """
        Fetch all markets from specified series

        Args:
            series_tickers: List of series tickers (e.g., KXLOWTDEN, KXLOWTMIA)

        Returns:
            List of market dictionaries
        """
        all_markets = []
        for series_ticker in series_tickers:
            try:
                self.logger.info(f"Fetching series: {series_ticker}")

                # Get all open markets for this series
                markets = self.kalshi.get_markets_for_series(series_ticker, status="open")

                # Format each market
                for market in markets:
                    formatted_market = {
                        "ticker": market["ticker"],
                        "title": market["title"],
                        "event_ticker": market.get("event_ticker", ""),
                        "close_time": market["close_time"],
                        "expiration_time": market.get("expiration_time", ""),
                        "yes_bid": market.get("yes_bid"),
                        "yes_ask": market.get("yes_ask"),
                        "no_bid": market.get("no_bid"),
                        "no_ask": market.get("no_ask"),
                        "volume": market.get("volume", 0),
                        "liquidity_pool": market.get("liquidity_pool"),
                        "category": market.get("category"),
                        "status": market.get("status"),
                    }
                    all_markets.append(formatted_market)

                self.logger.info(f"  âœ“ Found {len(markets)} markets in {series_ticker}")

            except Exception as e:
                self.logger.error(f"  âœ— Failed to fetch series {series_ticker}: {e}")
                continue

        self.logger.info(f"Total markets fetched from series: {len(all_markets)}")
        return all_markets

    def _fetch_specific_markets(self, tickers: List[str]) -> List[dict]:
        """
        Fetch specific markets by ticker

        Args:
            tickers: List of market tickers to fetch

        Returns:
            List of market dictionaries
        """
        markets = []
        for ticker in tickers:
            try:
                self.logger.info(f"Fetching market: {ticker}")
                market = self.kalshi.get_market(ticker)

                # Format market data to match promo_markets structure
                formatted_market = {
                    "ticker": market["ticker"],
                    "title": market["title"],
                    "event_ticker": market.get("event_ticker", ""),
                    "close_time": market["close_time"],
                    "expiration_time": market.get("expiration_time", ""),
                    "yes_bid": market.get("yes_bid"),
                    "yes_ask": market.get("yes_ask"),
                    "no_bid": market.get("no_bid"),
                    "no_ask": market.get("no_ask"),
                    "volume": market.get("volume", 0),
                    "liquidity_pool": market.get("liquidity_pool"),
                    "category": market.get("category"),
                    "status": market.get("status"),
                }
                markets.append(formatted_market)
                self.logger.info(f"  âœ“ Fetched: {market['title'][:70]}")

            except Exception as e:
                self.logger.error(f"  âœ— Failed to fetch {ticker}: {e}")
                continue

        return markets

    def _filter_weather_markets(self, markets: List[dict]) -> List[dict]:
        """
        Filter for weather markets in supported locations

        Args:
            markets: List of all markets

        Returns:
            List of weather markets for Denver/Miami
        """
        supported_locations = ["Denver", "Miami"]

        weather_markets = []
        for market in markets:
            title = market["title"].lower()

            # Check if it's a temperature/weather market (broader search)
            is_weather = any(keyword in title for keyword in [
                "temperature", "weather", "lowest", "highest", "warmest", "coldest"
            ])

            if not is_weather:
                continue

            # Check if it's for a supported location
            if any(loc.lower() in title for loc in supported_locations):
                weather_markets.append(market)

        return weather_markets

    def _parse_location(self, location: str) -> tuple:
        """
        Parse location string into city and state

        Args:
            location: Location string (e.g., "Denver, CO")

        Returns:
            Tuple of (city, state)
        """
        parts = location.split(",")
        if len(parts) != 2:
            return None, None

        city = parts[0].strip()
        state = parts[1].strip()

        return city, state

    def run_and_save(self, output_dir: str = "./reports") -> List[Opportunity]:
        """
        Run scan and save reports to disk

        Args:
            output_dir: Directory to save reports

        Returns:
            List of identified opportunities
        """
        # Create output directory
        Path(output_dir).mkdir(parents=True, exist_ok=True)

        # Run scan
        opportunities = self.scan()

        # Generate reports
        report_md = self.reporter.generate_daily_report(opportunities)
        report_csv = self.reporter.generate_csv_export(opportunities)

        # Save files with timestamp
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")

        md_path = f"{output_dir}/kalshi_report_{timestamp}.md"
        with open(md_path, "w") as f:
            f.write(report_md)
        self.logger.info(f"Saved Markdown report: {md_path}")

        csv_path = f"{output_dir}/kalshi_opportunities_{timestamp}.csv"
        with open(csv_path, "w") as f:
            f.write(report_csv)
        self.logger.info(f"Saved CSV export: {csv_path}")

        # Also save latest as current.md
        current_path = f"{output_dir}/current.md"
        with open(current_path, "w") as f:
            f.write(report_md)
        self.logger.info(f"Saved current report: {current_path}")

        # Print summary
        if opportunities:
            summary = self.reporter.generate_summary(opportunities)
            self.logger.info(f"\n{summary}\n")

        return opportunities
